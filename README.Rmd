#Getting & Cleaning Data Course Project
May 2015

###Overview
From course assignment page:
<https://class.coursera.org/getdata-014/human_grading/view/courses/973501/assessments/3/submissions>

You should create one R script called run_analysis.R that does the following:

* Merges the training and the test sets to create one data set.
* Extracts only the measurements on the mean and standard deviation for each measurement. 
* Uses descriptive activity names to name the activities in the data set
* Appropriately labels the data set with descriptive variable names. 
* From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.

###Source Data
#####Source:
<https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip>

#####Additional information:
<http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones>

#####Data Set Information (from "additional information" page):

The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data. 
The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. From each window, a vector of features was obtained by calculating variables from the time and frequency domain.
Check the README.txt file for further details about this dataset. 
A video of the experiment including an example of the 6 recorded activities with one of the participants can be seen in the following link: [Web Link]

#####Attribute Information (from "additional information" page):

For each record in the dataset it is provided: 
- Triaxial acceleration from the accelerometer (total acceleration) and the estimated body acceleration. 
- Triaxial Angular velocity from the gyroscope. 
- A 561-feature vector with time and frequency domain variables. 
- Its activity label. 
- An identifier of the subject who carried out the experiment.

#####Data Sets Used:
X_train.txt, Y_train.txt, subject_train.txt, 
X_test.txt, Y_test.txt, subject_test.txt, 
activity_labels.txt, features.txt

#####Data Set Overview:
* "test" or "train" indicates whether the data are for the test or the training group
* "x" indicates the measurements
* "y" indicates the activity code
* "subject" indicates the people being measured
* "activity_labels" file - relates the six activity codes to the six activities
* "features " file- names for each measurement column in x

###Process

####Merges the training and the test sets to create one data set.
Read the files into R data sets

```
getwd()
library(data.table)
library(stringr)
library(dplyr)
library(memisc)

# download zip
# NOTE: due to my firewall I had to download and unzip manually, so this block hasn't been tested
url<-"https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(url,destfile="./Dataset.zip",method="curl")
unzip(zipfile="./Dataset.zip",exdir=".")
# END untested block

xtrain<-read.table("X_train.txt")
ytrain<-read.table("Y_train.txt")
strain<-read.table("subject_train.txt")

xtest<-read.table("X_test.txt")
ytest<-read.table("Y_test.txt")
stest<-read.table("subject_test.txt")

activity<-read.table("activity_labels.txt")
features<-read.table("features.txt",head=FALSE)
```

Combine the data:
* Stack (rbind) test and train data by data type: x, y or s
* Add column names to the stacked datasets
* Combine (cbind) the stacked datasets into one dataset
* Add the activity names

```
### 1. Merges the training and the test sets to create one data set.

# add test/train group column to subject datasets
strain$group<-"train"
stest$group<-"test"

# merge: stack training and test data sets
alls<-rbind(strain,stest)
ally<-rbind(ytrain,ytest)
allx<-rbind(xtrain,xtest)

# name columns, TIDY: translate features to all lower case
names(alls)<-c("subject","group")
setnames(ally,"activitycode")
names(allx)<-tolower(features[,2])

# merge subjects, activity codes and measurements
combo<-cbind(alls,ally,allx)
colnames(combo)
```

####Extracts only the measurements on the mean and standard deviation for each measurement. 

Identify columns to keep:
* Subject and activity
* Measurements of means ("mean")
* Standard deviations ("std")
Add the activity names

```
### 2. Extracts only the measurements on the mean and standard deviation for each measurement. 

#identify columns to keep

cols<-grep("subject|group|activitycode|mean|std",colnames(combo))
cols

#extract columns

combokeep<-combo[,cols]
dim(combokeep)
```
####Uses descriptive activity names to name the activities in the data set
Add activity name, drop activity code

```
### 3. Uses descriptive activity names to name the activities in the data set

# rename activity data set columns
names(activity)<-c("activitycode","activityname")
activity

#add activity name to combokeep, default merges on common name: "activitycode"

combowithactivity<-merge(activity,combokeep)
dim(combowithactivity)
# [1] 10299    90 - verified merge

# TIDY: drop activitycode (redundant with activity name)
# note: in practice i'd probably keep it, easier to remerge later if needed

combowithactivity$activitycode<-NULL
dim(combowithactivity)
```

####Appropriately labels the data set with descriptive variable names. 

Make the data tidy:
Make the columns more readable by expanding the shortened name components and dropping special characters

```
### 4. Appropriately labels the data set with descriptive variable names. 

## TIDY: clarify column names based on README details:

# "(prefix 't' to denote time)..."
names(combowithactivity)<-gsub("^t","time",names(combowithactivity))

# "Also the magnitude of these three-dimensional signals were..."
names(combowithactivity)<-gsub("mag","magnitude",names(combowithactivity))

# "(Note the 'f' to indicate frequency domain signals)." 
names(combowithactivity)<-gsub("^f","freq",names(combowithactivity))

# "train/Inertial Signals/total_acc_x_train.txt': The acceleration signal..."
# 'train/Inertial Signals/body_acc_x_train.txt': The body acceleration signal..." 
names(combowithactivity)<-gsub("acc","acceleration",names(combowithactivity))

# "train/Inertial Signals/body_gyro_x_train.txt': 
# The angular velocity vector measured by the gyroscope..."
names(combowithactivity)<-gsub("gyro","gyroscope",names(combowithactivity))

# drop -(), characters
names(combowithactivity)<-gsub("-","",names(combowithactivity))
names(combowithactivity)<-gsub("\\(","",names(combowithactivity))
names(combowithactivity)<-gsub("\\)","",names(combowithactivity))
names(combowithactivity)<-gsub("\\,","",names(combowithactivity))

## TIDY: sort on group, subject, and activity

combowithactivity<-arrange(combowithactivity,group,subject,activityname)
```

####From the data set in step 4, creates a second, independent tidy data set 
####with the average of each variable for each activity and each subject.

Create the tidy summary dataset:
Calculate means for all mean and standard deviation measurement for each unique user and activity combination
NOTE: dropping "group" because the assignment doesn's say to create or keep, but I think it's an 
important variable to have in the underlying detailed data

```
DT <- data.table(combowithactivity)
DT$group<-NULL
mydata<-aggregate(.~subject+activityname,DT,mean)
mydata<-arrange(mydata,subject,activityname)

dim(mydata)

# write to text file for submission
write.table(mydata,"mydata.txt",row.name=FALSE)
```

Create the codebook

```
mydata<-within(mydata,{
        description(subject)<-"30 people measured in the study"
        description(activityname)<-"6 activities measured in study"
        
}
)
cboutput<-codebook(data.set(mydata))
capture.output(cboutput,file="codebook.Rmd")

```

Final data set is "wide tidy" per the discussion forum:
<https://class.coursera.org/getdata-014/forum/thread?thread_id=31>

Per Hadley's tidy data article (page four), data are tidy:
* Each variable forms a column (subject, activity, measurements)
* Each observation forms a row (unique subject and activity combinations)
* Each type of observational unit forms a table (means of normalized measurements)
<http://vita.had.co.nz/papers/tidy-data.pdf>

